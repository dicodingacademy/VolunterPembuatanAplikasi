{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZBgRyU6aAjFMgqBcdhHyU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fakhrulnurmulyana/VolunterPembuatanAplikasi/blob/main/HukumQ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h1>Chatbot HukumQ</h1>**"
      ],
      "metadata": {
        "id": "gXAmdaNu01M0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a0017DIvZU2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import nltk\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile content.json\n",
        "{\"intents\":\n",
        "  [\n",
        "    {\n",
        "      \"tag\" : \"sapaan\",\n",
        "      \"input\" : [\"Halo\", \"Selamat datang\", \"Apa kabar hari ini?\", \"Assalamualaikum\", \"Mari kita berbicara\", \"Apa kabar, teman?\", \"Salam kenal\",  \"Hai, kawan!\", \"Hai, sobat!\",  \"Salam sejahtera\", \"p\", \".\", \"Sampurasun\", \"baa kaba?\", \"oi\", \"oy\", \"spada\"],\n",
        "      \"responses\" : [\"Halo\", \"Selamat datang\", \"Bagaimana keadaanmu?\", \"Hai, apa kabarmu?\", \"Apa yang terjadi?\", \"Apa yang bisa saya bantu?\", \"Ada yang perlu diobrolkan?\", \"Apa kabar hari ini?\", \"Assalamualaikum\", \"Mari kita berbicara\", \"Apa kabar, teman?\", \"Salam kenal\", \"Hai juga\",  \"Hai, kawan!\", \"Hai, sobat!\",  \"Salam sejahtera\", \"Halo!\", \"Baik, terima kasih. Bagaimana denganmu?\", \"Terima kasih, senang berada di sini.\", \"Baik, terima kasih. Bagaimana denganmu?\", \"Hai! Kabarku baik, terima kasih. Bagaimana denganmu?\", \"Tidak ada yang spesial, bagaimana denganmu?\", \"Apa yang bisa saya bantu untukmu?\", \"Tentu, kita bisa obrolkan apa saja.\", \"Hari ini baik-baik saja, terima kasih. Bagaimana denganmu?\", \"Waalaikumsalam!\", \"Tentu, kita bisa berbicara.\", \"Semua baik, terima kasih. Bagaimana denganmu?\", \"Hai, teman! Bagaimana kabarmu?\", \"Tidak ada yang baru, apa kabar?\", \"Salam kenal juga!\", \"Hai juga!\", \"Hai, kawan! Apa kabar?\", \"Salam sejahtera!\", \"hai orang asing, apa yang kamu mau?\"]\n",
        "    }\n",
        "    {\n",
        "      \"tag\" : \"kabar\",\n",
        "      \"input\" : [],\n",
        "      \"responses\" : []\n",
        "    }\n",
        "    {\n",
        "      \"tag\" : \"siapa\",\n",
        "      \"input\" : [],\n",
        "      \"responses\" : []\n",
        "    }\n",
        "    {\n",
        "      \"tag\" : \"lokasi\",\n",
        "      \"input\" : [],\n",
        "      \"responses\" : []\n",
        "    }\n",
        "    {\n",
        "      \"tag\": \"hukum_umum\",\n",
        "      \"patterns\": [\"Apa itu hukum?\", \"Bagaimana proses peradilan bekerja?\"],\n",
        "      \"responses\": [\"Hukum adalah...\", \"Proses peradilan melibatkan...\"]\n",
        "    }\n",
        "    {\n",
        "      \"tag\" : \"\",\n",
        "      \"input\" : [],\n",
        "      \"responses\" : []\n",
        "    }\n",
        "    {\n",
        "      \"tag\" : \"\",\n",
        "      \"input\" : [],\n",
        "      \"responses\" : []\n",
        "    }\n",
        "    {\n",
        "      \"tag\" : \"\",\n",
        "      \"input\" : [],\n",
        "      \"responses\" : []\n",
        "    }\n",
        "    {\n",
        "      \"tag\" : \"\",\n",
        "      \"input\" : [],\n",
        "      \"responses\" : []\n",
        "    }\n",
        "    {\n",
        "      \"tag\" : \"\",\n",
        "      \"input\" : [],\n",
        "      \"responses\" : []\n",
        "    }\n",
        "    {\n",
        "      \"tag\" : \"\",\n",
        "      \"input\" : [],\n",
        "      \"responses\" : []\n",
        "    }\n",
        "    {\n",
        "      \"tag\" : \"\",\n",
        "      \"input\" : [],\n",
        "      \"responses\" : []\n",
        "    }\n",
        "    {\n",
        "      \"tag\" : \"pamitan\",\n",
        "      \"input\" : [\"terima kasih\", \"terimakasih\", \"terimakasih banyak\", \"terima kasih\", \"makasih\", \"dadah\", \"adios\", \"okay\", \"oke\", \"sampai bertemu lagi\", \"Sukses selalu.\", \"Hatur nuhun.\", \"Senang berinteraksi denganmu.\", \"Terima kasih atas bantuanmu.\", \"Berterima kasih atas dukunganmu.\", \"Semoga harimu menyenangkan.\", \"Sampai jumpa lain waktu.\", \"Terima kasih banyak ya!\", \"Semoga harimu penuh berkah.\", \"Sukses untukmu!\", \"Hingga kita kembali bertemu.\", \"Terima kasih atas waktu dan perhatiannya.\", \"Sehat selalu, ya!\", \"Semoga harimu indah seperti senyummu.\", \"Sampai jumpa di lain kesempatan.\", \"Semoga kebaikanmu berlipat ganda.\", \"Berterima kasih atas kerjasamanya.\", \"Sukses dan bahagia selalu.\", \"Semoga kesuksesan selalu menyertaimu.\", \"Mudah-mudahan hari esok lebih baik lagi.\", \"Semoga langkahmu selalu diberkahi.\", \"Terima kasih, semoga harimu menyenangkan.\", \"Sukses selalu dalam setiap langkahmu.\", \"Terima kasih atas kebaikanmu.\", \"Semoga kesuksesan senantiasa menyertaimu.\", \"Sampai jumpa di kesempatan berikutnya.\", \"Semoga kita bisa berinteraksi lagi nantinya.\", \"Terima kasih atas kerja samanya.\", \"Semoga hari-harimu selalu bahagia.\", \"Hingga kita bertemu lagi, terima kasih!\"],\n",
        "      \"responses\" : [\"Sama-sama, senang bisa membantu!\", \"Terima kasih juga atas kerja samanya.\", \"Sukses selalu untuk Anda juga!\", \"Semoga kita bisa berinteraksi lagi di lain waktu.\", \"Sampai jumpa, semoga harimu juga menyenangkan!\", \"Hatur nuhun, semoga harimu dipenuhi kebahagiaan.\", \"Terima kasih banyak ya! Semoga sukses terus.\", \"Senang berinteraksi denganmu juga, semoga harimu baik-baik saja.\", \"Adios! Hasta luego.\", \"Semoga langkahmu selalu diberkahi dan sukses.\", \"Makasih, semoga semua rencanamu berhasil dengan baik.\", \"Terima kasih atas dukunganmu, semoga kita bisa bertemu lagi.\", \"Sehat selalu, dan semoga kita bisa berkumpul lagi.\", \"Semoga harimu indah dan penuh canda tawa.\", \"Sukses dalam setiap langkahmu, sampai jumpa!\", \"Terima kasih atas waktu dan perhatiannya, semoga bermanfaat.\", \"Terima kasih, semoga harimu juga penuh berkah.\", \"Sampai jumpa di kesempatan berikutnya, semoga bahagia selalu.\", \"Terima kasih, semoga hari esok membawa kebaikan.\", \"Hatur nuhun, semoga kita bisa berkolaborasi lagi di masa depan.\"]\n",
        "    }\n",
        "    {\n",
        "      \"tag\": \"fallback\",\n",
        "      \"patterns\": [\"*\"],\n",
        "      \"responses\": [\"Maaf, saya tidak dapat memahami pertanyaan Anda. Bisakah Anda mencoba pertanyaan lain?\"]\n",
        "    }\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "tyPAtqYSwSgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Mengimport Data</h2>**"
      ],
      "metadata": {
        "id": "DVGUxfajzZ9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengimport dataset\n",
        "with open('content.json') as content :\n",
        "  data1 = json.load(content)"
      ],
      "metadata": {
        "id": "xcUUP9p6r3hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merubah data jadi lists\n",
        "tags = []\n",
        "inputs = []\n",
        "responses = {}\n",
        "for intent in data1[\"intents\"]:\n",
        "  responses[intent[\"tag\"]]=intent[\"responses\"]\n",
        "  for lines in intent[\"input\"]:\n",
        "    input.append(lines)\n",
        "    tags.append(intent['tag'])"
      ],
      "metadata": {
        "id": "y5_SyFKut1w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame({\"inputs\":inputs,\n",
        "                      \"tags\":tags})"
      ],
      "metadata": {
        "id": "Ddsa9h7SvSuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "z4ZJx-YIvrpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Pre-Processing</h2>**"
      ],
      "metadata": {
        "id": "UvaFrK6Qzvxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghilangkan tanda baca\n",
        "import string\n",
        "data[\"inputs\"] = data[\"inputs\"].apply(lamda wrd:[ltrs.lower() for ltrs in wrd if ltrs in wrd if ltrs not in string.punctation])\n",
        "data[\"inputs\"] = data[\"inputs\"].apply(lamda wrd: \"\".join(wrd))\n",
        "data"
      ],
      "metadata": {
        "id": "OKILqqCGyvaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words = 2000)\n",
        "tokenizer.fit_on_text(data[\"inputs\"])\n",
        "train = tokenizer.text_to_sequences(data[\"inputs\"])\n",
        "# Apply padding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train = pad_sequences(train)\n",
        "\n",
        "# Encoding the outputs\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(data[\"tags\"])"
      ],
      "metadata": {
        "id": "0QFf9gRu1It8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = x_train.shape[1]\n",
        "print(input_shape)"
      ],
      "metadata": {
        "id": "POVymTQU28Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendefenisikan Vocabulary\n",
        "vocabulary = len(tokenizer.word_index)\n",
        "print(\"number of unique words : \", vocabulary)\n",
        "output_length = le.classes_shape[0]\n",
        "print(\"output length : \", output_length)"
      ],
      "metadata": {
        "id": "nK-OHjI_5RuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Train (Neural Network)</h2>**"
      ],
      "metadata": {
        "id": "PPqXG_010uGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM\n",
        "\n",
        "#i = Input(shape = (input_shape))\n",
        "#x = Embedding(vocabulary+1, 10) (i)\n",
        "#x = LSTM(10, return_sequences=True)(x)\n",
        "#x = Flatten()(x)\n",
        "#x = Dense(output_length, activation=\"softmax\")(x)\n",
        "#model = Model(i,x)\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocabulary + 1, 10, input_shape=(input_shape,)),\n",
        "    LSTM(10, return_sequences=True),\n",
        "    Flatten(),\n",
        "    Dense(output_length, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "hNHNnp4c0ygH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compile\n",
        "\n",
        "model.compile(loss = \"sparse_categorical_crossentropy\",\n",
        "              optimizer = \"adam\",\n",
        "              mentrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "RfvmplD47hOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "#train = model.fit(x_train, y_train, epochs =200)"
      ],
      "metadata": {
        "id": "iV4F2DoZ8lrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Model Analisis</h2>**"
      ],
      "metadata": {
        "id": "AfZV1P2x9u7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting akurasi\n",
        "plt.plot(train.history[\"accuracy\"], label= \"training set accuracy\")\n",
        "plt.plot(train.history[\"loss\"], label= \"traiing set loss\" )\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "5KhgzXJ39O6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Testing</h2>**"
      ],
      "metadata": {
        "id": "qrfzsQXY-jDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#chatting\n",
        "import random\n",
        "\n",
        "while True:\n",
        "  text_p = []\n",
        "  prediction_input = input(\"you :\")\n",
        "\n",
        "  # Pre-Processing input\n",
        "  prediction_input = [letters.lower() for latters in prediction_input if latters not in string.punctation]\n",
        "  prediction_input = ' '.join(prediction_input)\n",
        "  text_p.append(pridiction_input)\n",
        "\n",
        "  # Tokenizer dan Padding input\n",
        "  prediction_input = tokenizer.text_to_sequences(text_p)\n",
        "  prediction_input = np.array(prediction_input).reshape(-1)\n",
        "  prediction_input = pad_sequences([prediction_input], input_shape)\n",
        "\n",
        "  # Mendapatkan output dari model\n",
        "  output = model.predict(prediction_input)\n",
        "  output = output.argmax()\n",
        "\n",
        "  # Mencari tag yang sesuai\n",
        "  response_tag = le.inverse_transform([output])[0]\n",
        "  print(\"HukumQ :\", random.choice(response[response_tag]))\n",
        "  if response_tag == \"goodbye\" :\n",
        "    break\n"
      ],
      "metadata": {
        "id": "-yrDHN8S-bYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>kesimpulan</h2>**"
      ],
      "metadata": {
        "id": "B_ER38GnA_6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RL-yjDcSBEAO"
      }
    }
  ]
}